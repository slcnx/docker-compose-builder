{
  "url": "https://eemeli.org/yaml/",
  "metadata": {
    "title": "YAML â€“ YAML",
    "description": "",
    "keywords": [],
    "author": "",
    "publish_date": "",
    "domain": "eemeli.org"
  },
  "content": "[ NAV ![](https://eemeli.org/yaml/images/navbar-cad8cdcb.png) ](https://eemeli.org/yaml/)\n\n![](https://eemeli.org/yaml/images/logo-ff1f79b2.png)\n\n\n\n  * [YAML](https://eemeli.org/yaml/#yaml)\n    * [API Overview](https://eemeli.org/yaml/#api-overview)\n  * [Parse & Stringify](https://eemeli.org/yaml/#parse-amp-stringify)\n    * [YAML.parse](https://eemeli.org/yaml/#yaml-parse)\n    * [YAML.stringify](https://eemeli.org/yaml/#yaml-stringify)\n  * [Options](https://eemeli.org/yaml/#options)\n    * [Parse Options](https://eemeli.org/yaml/#parse-options)\n    * [Document Options](https://eemeli.org/yaml/#document-options)\n    * [Schema Options](https://eemeli.org/yaml/#schema-options)\n    * [CreateNode Options](https://eemeli.org/yaml/#createnode-options)\n    * [ToJS Options](https://eemeli.org/yaml/#tojs-options)\n    * [ToString Options](https://eemeli.org/yaml/#tostring-options)\n  * [Documents](https://eemeli.org/yaml/#documents)\n    * [Parsing Documents](https://eemeli.org/yaml/#parsing-documents)\n    * [Creating Documents](https://eemeli.org/yaml/#creating-documents)\n    * [Document Methods](https://eemeli.org/yaml/#document-methods)\n    * [Stream Directives](https://eemeli.org/yaml/#stream-directives)\n  * [Content Nodes](https://eemeli.org/yaml/#content-nodes)\n    * [Scalar Values](https://eemeli.org/yaml/#scalar-values)\n    * [Collections](https://eemeli.org/yaml/#collections)\n    * [Alias Nodes](https://eemeli.org/yaml/#alias-nodes)\n    * [Creating Nodes](https://eemeli.org/yaml/#creating-nodes)\n    * [Finding and Modifying Nodes](https://eemeli.org/yaml/#finding-and-modifying-nodes)\n    * [Identifying Node Types](https://eemeli.org/yaml/#identifying-node-types)\n    * [Comments and Blank Lines](https://eemeli.org/yaml/#comments-and-blank-lines)\n  * [Custom Data Types](https://eemeli.org/yaml/#custom-data-types)\n    * [Built-in Custom Tags](https://eemeli.org/yaml/#built-in-custom-tags)\n    * [Writing Custom Tags](https://eemeli.org/yaml/#writing-custom-tags)\n  * [Parsing YAML](https://eemeli.org/yaml/#parsing-yaml)\n    * [Lexer](https://eemeli.org/yaml/#lexer)\n    * [Parser](https://eemeli.org/yaml/#parser)\n    * [Composer](https://eemeli.org/yaml/#composer)\n    * [Working with CST Tokens](https://eemeli.org/yaml/#working-with-cst-tokens)\n  * [Errors](https://eemeli.org/yaml/#errors)\n    * [Silencing Errors and Warnings](https://eemeli.org/yaml/#silencing-errors-and-warnings)\n  * [Command-line Tool](https://eemeli.org/yaml/#command-line-tool)\n  * [YAML Syntax](https://eemeli.org/yaml/#yaml-syntax)\n    * [Tags](https://eemeli.org/yaml/#tags)\n    * [Version Differences](https://eemeli.org/yaml/#version-differences)\n\n\n  * [Version 2.8.1 (changelog)](https://github.com/eemeli/yaml/releases)\n  * [github.com/eemeli/yaml](https://github.com/eemeli/yaml)\n  * [`npm install yaml`](https://www.npmjs.com/package/yaml)\n\n\n\n# YAML\n\n> To install:\n    \n    \n    npm install yaml\n    # or\n    deno add jsr:@eemeli/yaml\n    \n\n> To use:\n    \n    \n    import { parse, stringify } from 'yaml'\n    // or\n    import YAML from 'yaml'\n    // or\n    const YAML = require('yaml')\n    \n\n`yaml` is a definitive library for [YAML](http://yaml.org/), the human friendly data serialization standard. This library:\n\n  * Supports both YAML 1.1 and YAML 1.2 and all common data schemas,\n  * Passes all of the [yaml-test-suite](https://github.com/yaml/yaml-test-suite) tests,\n  * Can accept any string as input without throwing, parsing as much YAML out of it as it can, and\n  * Supports parsing, modifying, and writing YAML comments and blank lines.\n\n\n\nThe library is released under the ISC open source license, and the code is [available on GitHub](https://github.com/eemeli/yaml/). It has no external dependencies and runs on Node.js as well as modern browsers.\n\nFor the purposes of versioning, any changes that break any of the endpoints or APIs documented here will be considered semver-major breaking changes. Undocumented library internals may change between minor versions, and previous APIs may be deprecated (but not removed).\n\nThe minimum supported TypeScript version of the included typings is 3.9; for use in earlier versions you may need to set `skipLibCheck: true` in your config. This requirement may be updated between minor versions of the library.\n\nFor build instructions and contribution guidelines, see [docs/CONTRIBUTING.md](https://github.com/eemeli/yaml/blob/main/docs/CONTRIBUTING.md) in the repo.\n\n**Note:** These docs are for `yaml@2`. For v1, see the [v1.10.0 tag](https://github.com/eemeli/yaml/tree/v1.10.0) for the source and [eemeli.org/yaml/v1](https://eemeli.org/yaml/v1/) for the documentation.\n\n## API Overview\n\nThe API provided by `yaml` has three layers, depending on how deep you need to go: [Parse & Stringify](https://eemeli.org/yaml/#parse-amp-stringify), [Documents](https://eemeli.org/yaml/#documents), and the underlying [Lexer/Parser/Composer](https://eemeli.org/yaml/#parsing-yaml). The first has the simplest API and \"just works\", the second gets you all the bells and whistles supported by the library along with a decent [AST](https://eemeli.org/yaml/#content-nodes), and the third lets you get progressively closer to YAML source, if that's your thing.\n\nA [command-line tool](https://eemeli.org/yaml/#command-line-tool) is also included.\n\n### Parse & Stringify\n    \n    \n    import { parse, stringify } from 'yaml'\n    \n\n  * [`parse(str, reviver?, options?): value`](https://eemeli.org/yaml/#yaml-parse)\n  * [`stringify(value, replacer?, options?): string`](https://eemeli.org/yaml/#yaml-stringify)\n\n\n\n### Documents\n    \n    \n    import {\n      Document,\n      isDocument,\n      parseAllDocuments,\n      parseDocument\n    } from 'yaml'\n    \n\n  * [`Document`](https://eemeli.org/yaml/#documents)\n    * [`constructor(value, replacer?, options?)`](https://eemeli.org/yaml/#creating-documents)\n    * [`#contents`](https://eemeli.org/yaml/#content-nodes)\n    * [`#directives`](https://eemeli.org/yaml/#stream-directives)\n    * [`#errors`](https://eemeli.org/yaml/#errors)\n    * [`#warnings`](https://eemeli.org/yaml/#errors)\n  * [`parseAllDocuments(str, options?): Document[]`](https://eemeli.org/yaml/#parsing-documents)\n  * [`parseDocument(str, options?): Document`](https://eemeli.org/yaml/#parsing-documents)\n\n\n\n### Content Nodes\n    \n    \n    import {\n      isAlias, isCollection, isMap, isNode,\n      isPair, isScalar, isSeq, Scalar,\n      visit, visitAsync, YAMLMap, YAMLSeq\n    } from 'yaml'\n    \n\n  * [`is*(foo): boolean`](https://eemeli.org/yaml/#identifying-node-types)\n  * [`new Scalar(value)`](https://eemeli.org/yaml/#scalar-values)\n  * [`new YAMLMap()`](https://eemeli.org/yaml/#collections)\n  * [`new YAMLSeq()`](https://eemeli.org/yaml/#collections)\n  * [`doc.createAlias(node, name?): Alias`](https://eemeli.org/yaml/#creating-nodes)\n  * [`doc.createNode(value, options?): Node`](https://eemeli.org/yaml/#creating-nodes)\n  * [`doc.createPair(key, value): Pair`](https://eemeli.org/yaml/#creating-nodes)\n  * [`visit(node, visitor)`](https://eemeli.org/yaml/#finding-and-modifying-nodes)\n  * [`visitAsync(node, visitor)`](https://eemeli.org/yaml/#finding-and-modifying-nodes)\n\n\n\n### Parsing YAML\n    \n    \n    import { Composer, Lexer, Parser } from 'yaml'\n    \n\n  * [`new Lexer().lex(src)`](https://eemeli.org/yaml/#lexer)\n  * [`new Parser(onNewLine?).parse(src)`](https://eemeli.org/yaml/#parser)\n  * [`new Composer(options?).compose(tokens)`](https://eemeli.org/yaml/#composer)\n\n\n\n# Parse & Stringify\n    \n    \n    # file.yml\n    YAML:\n      - A human-readable data serialization language\n      - https://en.wikipedia.org/wiki/YAML\n    yaml:\n      - A complete JavaScript implementation\n      - https://www.npmjs.com/package/yaml\n    \n\nAt its simplest, you can use `YAML.parse(str)` and `YAML.stringify(value)` just as you'd use `JSON.parse(str)` and `JSON.stringify(value)`. If that's enough for you, everything else in these docs is really just implementation details.\n\n## YAML.parse\n    \n    \n    import fs from 'fs'\n    import YAML from 'yaml'\n    \n    YAML.parse('3.14159')\n    // 3.14159\n    \n    YAML.parse('[ true, false, maybe, null ]\\n')\n    // [ true, false, 'maybe', null ]\n    \n    const file = fs.readFileSync('./file.yml', 'utf8')\n    YAML.parse(file)\n    // { YAML:\n    //   [ 'A human-readable data serialization language',\n    //     'https://en.wikipedia.org/wiki/YAML' ],\n    //   yaml:\n    //   [ 'A complete JavaScript implementation',\n    //     'https://www.npmjs.com/package/yaml' ] }\n    \n\n#### `YAML.parse(str, reviver?, options = {}): any`\n\n`str` should be a string with YAML formatting. If defined, the `reviver` function follows the [JSON implementation](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse#Using_the_reviver_parameter). See [Options](https://eemeli.org/yaml/#options) for more information on the last argument, an optional configuration object.\n\nThe returned value will match the type of the root value of the parsed YAML document, so Maps become objects, Sequences arrays, and scalars result in nulls, booleans, numbers and strings.\n\n`YAML.parse` may throw on error, and it may log warnings using `console.warn`. It only supports input consisting of a single YAML document; for multi-document support you should use [`YAML.parseAllDocuments`](https://eemeli.org/yaml/#parsing-documents).\n\n## YAML.stringify\n    \n    \n    YAML.stringify(3.14159)\n    // '3.14159\\n'\n    \n    YAML.stringify([true, false, 'maybe', null])\n    // `- true\n    // - false\n    // - maybe\n    // - null\n    // `\n    \n    YAML.stringify({ number: 3, plain: 'string', block: 'two\\nlines\\n' })\n    // `number: 3\n    // plain: string\n    // block: >\n    //   two\n    //\n    //   lines\n    // `\n    \n\n#### `YAML.stringify(value, replacer?, options = {}): string`\n\n`value` can be of any type. The returned string will always include `\\n` as the last character, as is expected of YAML documents. If defined, the `replacer` array or function follows the [JSON implementation](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#The_replacer_parameter). See [Options](https://eemeli.org/yaml/#options) for more information on the last argument, an optional configuration object. For JSON compatibility, using a number or a string as the `options` value will set the `indent` option accordingly.\n\nAs strings in particular may be represented in a number of different styles, the simplest option for the value in question will always be chosen, depending mostly on the presence of escaped or control characters and leading & trailing whitespace.\n\nTo create a stream of documents, you may call `YAML.stringify` separately for each document's `value`, and concatenate the documents with the string `...\\n` as a separator.\n\n# Options\n    \n    \n    import { parse, stringify } from 'yaml'\n    \n    parse('number: 999')\n    // { number: 999 }\n    \n    parse('number: 999', { intAsBigInt: true })\n    // { number: 999n }\n    \n    parse('number: 999', { schema: 'failsafe' })\n    // { number: '999' }\n    \n\nThe options supported by various `yaml` features are split into various categories, depending on how and where they are used. Options in various categories do not overlap, so it's fine to use a single \"bag\" of options and pass it to each function or method.\n\n## Parse Options\n\nParse options affect the parsing and composition of a YAML Document from it source.\n\nUsed by: `parse()`, `parseDocument()`, `parseAllDocuments()`, `new Composer()`, and `new Document()`\n\nName | Type | Default | Description  \n---|---|---|---  \nintAsBigInt | `boolean` | `false` | Whether integers should be parsed into [BigInt](https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/BigInt) rather than `number` values.  \nkeepSourceTokens | `boolean` | `false` | Include a `srcToken` value on each parsed `Node`, containing the [CST token](https://eemeli.org/yaml/#working-with-cst-tokens) that was composed into this node.  \nlineCounter | `LineCounter` |  | If set, newlines will be tracked, to allow for `lineCounter.linePos(offset)` to provide the `{ line, col }` positions within the input.  \nprettyErrors | `boolean` | `true` | Include line/col position in errors, along with an extract of the source string.  \nstrict | `boolean` | `true` | When parsing, do not ignore errors [required](https://eemeli.org/yaml/#silencing-errors-and-warnings) by the YAML 1.2 spec, but caused by unambiguous content.  \nstringKeys | `boolean` | `false` | Parse all mapping keys as strings. Treat all non-scalar keys as errors.  \nuniqueKeys | `boolean âŽ® (a, b) => boolean` | `true` | Whether key uniqueness is checked, or customised. If set to be a function, it will be passed two parsed nodes and should return a boolean value indicating their equality.  \n  \n## Document Options\n\nDocument options are relevant for operations on the `Document` object, which makes them relevant for both conversion directions.\n\nUsed by: `parse()`, `parseDocument()`, `parseAllDocuments()`, `stringify()`, `new Composer()`, and `new Document()`\n\nName | Type | Default | Description  \n---|---|---|---  \nlogLevel | `'warn' âŽ® 'error' âŽ®` `'silent'` | `'warn'` | Control the verbosity of `parse()`. Set to `'error'` to silence warnings, and to `'silent'` to also silence most errors (not recommended).  \nversion | `'1.1' âŽ® '1.2'` | `'1.2'` | The YAML version used by documents without a `%YAML` directive.  \n  \nBy default, the library will emit warnings as required by the YAML spec during parsing. If you'd like to silence these, set the `logLevel` option to `'error'`.\n\n## Schema Options\n    \n    \n    parse('3') // 3 (Using YAML 1.2 core schema by default)\n    parse('3', { schema: 'failsafe' }) // '3'\n    \n    parse('No') // 'No'\n    parse('No', { schema: 'json' }) // SyntaxError: Unresolved plain scalar \"No\"\n    parse('No', { schema: 'yaml-1.1' }) // false\n    parse('No', { version: '1.1' }) // false\n    \n\nSchema options determine the types of values that the document supports.\n\nAside from defining the language structure, the YAML 1.2 spec defines a number of different _schemas_ that may be used. The default is the [`core`](http://yaml.org/spec/1.2/spec.html#id2804923) schema, which is the most common one. The [`json`](http://yaml.org/spec/1.2/spec.html#id2803231) schema is effectively the minimum schema required to parse JSON; both it and the core schema are supersets of the minimal [`failsafe`](http://yaml.org/spec/1.2/spec.html#id2802346) schema.\n\nThe `yaml-1.1` schema matches the more liberal [YAML 1.1 types](http://yaml.org/type/) (also used by YAML 1.0), including binary data and timestamps as distinct tags. This schema accepts a greater variance in scalar values (with e.g. `'No'` being parsed as `false` rather than a string value). The `!!value` and `!!yaml` types are not supported.\n\nUsed by: `parse()`, `parseDocument()`, `parseAllDocuments()`, `stringify()`, `new Composer()`, `new Document()`, and `doc.setSchema()`\n\nName | Type | Default | Description  \n---|---|---|---  \ncompat | `string âŽ® Tag[] âŽ® null` | `null` | When parsing, warn about compatibility issues with the given schema. When stringifying, use scalar styles that are parsed correctly by the `compat` schema as well as the actual schema.  \ncustomTags | `Tag[] âŽ® function` |  | Array of [additional tags](https://eemeli.org/yaml/#custom-data-types) to include in the schema  \nmerge | `boolean` | 1.1: `true` 1.2: `false` | Enable support for `<<` merge keys. Default value depends on YAML version.  \nresolveKnownTags | `boolean` | `true` | When using the `'core'` schema, support parsing values with these explicit [YAML 1.1 tags](https://yaml.org/type/): `!!binary`, `!!omap`, `!!pairs`, `!!set`, `!!timestamp`. By default `true`.  \nschema | `string âŽ® Schema` | 1.1: `'yaml-1.1'` 1.2: `'core'` | The base schema to use. Default value depends on YAML version. Built-in support is provided for `'core'`, `'failsafe'`, `'json'`, and `'yaml-1.1'`. If using another string value, `customTags` must be an array of tags.  \nsortMapEntries | `boolean âŽ®` `(a, b: Pair) => number` | `false` | When stringifying, sort map entries. If `true`, sort by comparing key values using the native less-than `<` operator.  \ntoStringDefaults | `ToStringOptions` |  | Override default values for `toString()` options.  \n      \n    \n    const src = `\n      source: &base { a: 1, b: 2 }\n      target:\n        <<: *base\n        b: base`\n    const mergeResult = parse(src, { merge: true })\n    mergeResult.target\n    // { a: 1, b: 'base' }\n    \n\n**Merge** keys are a [YAML 1.1 feature](http://yaml.org/type/merge.html) that is not a part of the 1.2 spec. To use a merge key, assign a map or its alias or an array of such as the value of a `<<` key in a mapping. Multiple merge keys may be used on the same map, with earlier values taking precedence over latter ones, in case both define a value for the same key.\n\n## CreateNode Options\n\nUsed by: `stringify()`, `new Document()`, `doc.createNode()`, and `doc.createPair()`\n\nName | Type | Default | Description  \n---|---|---|---  \naliasDuplicateObjects | `boolean` | `true` | During node construction, use anchors and aliases to keep strictly equal non-null objects as equivalent in YAML.  \nanchorPrefix | `string` | `'a'` | Default prefix for anchors, resulting in anchors `a1`, `a2`, ... by default.  \nflow | `boolean` | `false` | Force the top-level collection node to use flow style.  \nkeepUndefined | `boolean` | `false` | Keep `undefined` object values when creating mappings and return a Scalar node when stringifying `undefined`.  \ntag | `string` |  | Specify the top-level collection type, e.g. `'!!omap'`. Note that this requires the corresponding tag to be available in this document's schema.  \n  \n## ToJS Options\n    \n    \n    parse('{[1, 2]: many}') // { '[ 1, 2 ]': 'many' }\n    parse('{[1, 2]: many}', { mapAsMap: true }) // Map { [ 1, 2 ] => 'many' }\n    \n\nThese options influence how the document is transformed into \"native\" JavaScript representation.\n\nUsed by: `parse()`, `doc.toJS()` and `node.toJS()`\n\nName | Type | Default | Description  \n---|---|---|---  \nmapAsMap | `boolean` | `false` | Use Map rather than Object to represent mappings.  \nmaxAliasCount | `number` | `100` | Prevent [exponential entity expansion attacks](https://en.wikipedia.org/wiki/Billion_laughs_attack) by limiting data aliasing; set to `-1` to disable checks; `0` disallows all alias nodes.  \nonAnchor | `(value: any, count: number) => void` |  | Optional callback for each aliased anchor in the document.  \nreviver | `(key: any, value: any) => any` |  | Optionally apply a [reviver function](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse#Using_the_reviver_parameter) to the output, following the JSON specification but with appropriate extensions for handling `Map` and `Set`.  \n  \n## ToString Options\n    \n    \n    stringify(\n      { this: null, that: 'value' },\n      { defaultStringType: 'QUOTE_SINGLE', nullStr: '~' }\n    )\n    // 'this': ~\n    // 'that': 'value'\n    \n\nThe `doc.toString()` method may be called with additional options to control the resulting YAML string representation of the document.\n\nUsed by: `stringify()` and `doc.toString()`\n\nName | Type | Default | Description  \n---|---|---|---  \nblockQuote | `boolean âŽ® 'folded' âŽ® 'literal'` | `true` | Use block quote styles for scalar values where applicable. Set to `false` to disable block quotes completely.  \ncollectionStyle | `'any' âŽ® 'block' âŽ® 'flow'` | `'any'` | Enforce `'block'` or `'flow'` style on maps and sequences. By default, allows each collection to set its own `flow: boolean` property.  \ncommentString | `(comment: string) => string` |  | Output should be valid for the current schema. By default, empty comment lines are left empty, lines consisting of a single space are replaced by `#`, and all other lines are prefixed with a `#`.  \ndefaultKeyType | `'BLOCK_FOLDED' âŽ® 'BLOCK_LITERAL' âŽ®` `'QUOTE_DOUBLE' âŽ® 'QUOTE_SINGLE' âŽ®` `'PLAIN' âŽ® null` | `null` | If not `null`, overrides `defaultStringType` for implicit key values.  \ndefaultStringType | `'BLOCK_FOLDED' âŽ® 'BLOCK_LITERAL' âŽ®` `'QUOTE_DOUBLE' âŽ® 'QUOTE_SINGLE' âŽ®` `'PLAIN'` | `'PLAIN'` | The default type of string literal used to stringify values.  \ndirectives | `boolean âŽ® null` | `null` | Include directives in the output. If `true`, at least the document-start marker `---` is always included. If `false`, no directives or marker is ever included. If `null`, directives and marker may be included if required.  \ndoubleQuotedAsJSON | `boolean` | `false` | Restrict double-quoted strings to use JSON-compatible syntax.  \ndoubleQuotedMinMultiLineLength | `number` | `40` | Minimum length for double-quoted strings to use multiple lines to represent the value instead of escaping newlines.  \nfalseStr | `string` | `'false'` | String representation for `false` values.  \nflowCollectionPadding | `boolean` | `true` | When true, a single space of padding will be added inside the delimiters of non-empty single-line flow collections.  \nindent | `number` | `2` | The number of spaces to use when indenting code. Should be a strictly positive integer.  \nindentSeq | `boolean` | `true` | Whether block sequences should be indented.  \nlineWidth | `number` | `80` | Maximum line width (set to `0` to disable folding). This is a soft limit, as only double-quoted semantics allow for inserting a line break in the middle of a word.  \nminContentWidth | `number` | `20` | Minimum line width for highly-indented content (set to `0` to disable). Ignored if greater than lineWidth.  \nnullStr | `string` | `'null'` | String representation for `null` values.  \nsimpleKeys | `boolean` | `false` | Require keys to be scalars and always use implicit rather than explicit notation.  \nsingleQuote | `boolean âŽ® null` | `null` | Use 'single quote' rather than \"double quote\" where applicable. Set to `false` to disable single quotes completely.  \ntrueStr | `string` | `'true'` | String representation for `true` values.  \n  \n# Documents\n\nIn order to work with YAML features not directly supported by native JavaScript data types, such as comments, anchors and aliases, `yaml` provides the `Document` API.\n\n## Parsing Documents\n    \n    \n    import fs from 'fs'\n    import { parseAllDocuments, parseDocument } from 'yaml'\n    \n    const file = fs.readFileSync('./file.yml', 'utf8')\n    const doc = parseDocument(file)\n    doc.contents\n    // YAMLMap {\n    //   items:\n    //    [ Pair {\n    //        key: Scalar { value: 'YAML', range: [ 0, 4, 4 ] },\n    //        value:\n    //         YAMLSeq {\n    //           items:\n    //            [ Scalar {\n    //                value: 'A human-readable data serialization language',\n    //                range: [ 10, 54, 55 ] },\n    //              Scalar {\n    //                value: 'https://en.wikipedia.org/wiki/YAML',\n    //                range: [ 59, 93, 94 ] } ],\n    //           range: [ 8, 94, 94 ] } },\n    //      Pair {\n    //        key: Scalar { value: 'yaml', range: [ 94, 98, 98 ] },\n    //        value:\n    //         YAMLSeq {\n    //           items:\n    //            [ Scalar {\n    //                value: 'A complete JavaScript implementation',\n    //                range: [ 104, 140, 141 ] },\n    //              Scalar {\n    //                value: 'https://www.npmjs.com/package/yaml',\n    //                range: [ 145, 180, 180 ] } ],\n    //           range: [ 102, 180, 180 ] } } ],\n    //   range: [ 0, 180, 180 ] }\n    \n\nThese functions should never throw, provided that `str` is a string and the `options` are valid. Errors and warnings are included in the documents' `errors` and `warnings` arrays. In particular, if `errors` is not empty it's likely that the document's parsed `contents` are not entirely correct.\n\nThe `contents` of a parsed document will always consist of `Scalar`, `Map`, `Seq` or `null` values.\n\n#### `parseDocument(str, options = {}): Document`\n\nParses a single `Document` from the input `str`; used internally by `parse`. Will include an error if `str` contains more than one document. See [Options](https://eemeli.org/yaml/#options) for more information on the second parameter.\n\n  \n\n\n#### `parseAllDocuments(str, options = {}): Document[]`\n\nWhen parsing YAML, the input string `str` may consist of a stream of documents separated from each other by `...` document end marker lines. `parseAllDocuments` will return an array of `Document` objects that allow these documents to be parsed and manipulated with more control. See [Options](https://eemeli.org/yaml/#options) for more information on the second parameter.\n\n  \n\n\n## Creating Documents\n\n#### `new Document(value, replacer?, options = {})`\n\nCreates a new document. If `value` is defined, the document `contents` are initialised with that value, wrapped recursively in appropriate [content nodes](https://eemeli.org/yaml/#content-nodes). If `value` is `undefined`, the document's `contents` is initialised as `null`. If defined, a `replacer` may filter or modify the initial document contents, following the same algorithm as the [JSON implementation](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#The_replacer_parameter). See [Options](https://eemeli.org/yaml/#options) for more information on the last argument.\n\nMember | Type | Description  \n---|---|---  \ncommentBefore | `string?` | A comment at the very beginning of the document. If not empty, separated from the rest of the document by a blank line or the doc-start indicator when stringified.  \ncomment | `string?` | A comment at the end of the document. If not empty, separated from the rest of the document by a blank line when stringified.  \ncontents | [`Node`](https://eemeli.org/yaml/#content-nodes) `âŽ® any` | The document contents.  \ndirectives | [`Directives`](https://eemeli.org/yaml/#stream-directives) | Controls for the `%YAML` and `%TAG` directives, as well as the doc-start marker `---`.  \nerrors | [`Error[]`](https://eemeli.org/yaml/#errors) | Errors encountered during parsing.  \nschema | `Schema` | The schema used with the document.  \nwarnings | [`Error[]`](https://eemeli.org/yaml/#errors) | Warnings encountered during parsing.  \n      \n    \n    import { Document } from 'yaml'\n    \n    const doc = new Document(['some', 'values', { balloons: 99 }])\n    doc.commentBefore = ' A commented document'\n    \n    String(doc)\n    // # A commented document\n    //\n    // - some\n    // - values\n    // - balloons: 99\n    \n\nThe Document members are all modifiable, though it's unlikely that you'll have reason to change `errors`, `schema` or `warnings`. In particular you may be interested in both reading and writing **`contents`**. Although `parseDocument()` and `parseAllDocuments()` will leave it with `YAMLMap`, `YAMLSeq`, `Scalar` or `null` contents, it can be set to anything.\n\n## Document Methods\n\nMethod | Returns | Description  \n---|---|---  \nclone() | `Document` | Create a deep copy of this Document and its contents. Custom Node values that inherit from `Object` still refer to their original instances.  \ncreateAlias(node: Node, name?: string) | `Alias` | Create a new `Alias` node, adding the required anchor for `node`. If `name` is empty, a new anchor name will be generated.  \ncreateNode(value, options?) | `Node` | Recursively wrap any input with appropriate `Node` containers. See [Creating Nodes](https://eemeli.org/yaml/#creating-nodes) for more information.  \ncreatePair(key, value, options?) | `Pair` | Recursively wrap `key` and `value` into a `Pair` object. See [Creating Nodes](https://eemeli.org/yaml/#creating-nodes) for more information.  \nsetSchema(version, options?) | `void` | Change the YAML version and schema used by the document. `version` must be either `'1.1'` or `'1.2'`; accepts all Schema options.  \ntoJS(options?) | `any` | A plain JavaScript representation of the document `contents`.  \ntoJSON() | `any` | A JSON representation of the document `contents`.  \ntoString(options?) | `string` | A YAML representation of the document.  \n      \n    \n    const doc = parseDocument('a: 1\\nb: [2, 3]\\n')\n    doc.get('a') // 1\n    doc.getIn([]) // YAMLMap { items: [Pair, Pair], ... }\n    doc.hasIn(['b', 0]) // true\n    doc.addIn(['b'], 4) // -> doc.get('b').items.length === 3\n    doc.deleteIn(['b', 1]) // true\n    doc.getIn(['b', 1]) // 4\n    \n\nIn addition to the above, the document object also provides the same **accessor methods** as [collections](https://eemeli.org/yaml/#collections), based on the top-level collection: `add`, `delete`, `get`, `has`, and `set`, along with their deeper variants `addIn`, `deleteIn`, `getIn`, `hasIn`, and `setIn`. For the `*In` methods using an empty `path` value (i.e. `null`, `undefined`, or `[]`) will refer to the document's top-level `contents`.\n\n#### `Document#toJS()`, `Document#toJSON()` and `Document#toString()`\n    \n    \n    const src = '1969-07-21T02:56:15Z'\n    const doc = parseDocument(src, { customTags: ['timestamp'] })\n    \n    doc.toJS()\n    // Date { 1969-07-21T02:56:15.000Z }\n    \n    doc.toJSON()\n    // '1969-07-21T02:56:15.000Z'\n    \n    String(doc)\n    // '1969-07-21T02:56:15\\n'\n    \n\nFor a plain JavaScript representation of the document, **`toJS(options = {})`** is your friend. Its output may include `Map` and `Set` collections (e.g. if the `mapAsMap` option is true) and complex scalar values like `Date` for `!!timestamp`, but all YAML nodes will be resolved. See [Options](https://eemeli.org/yaml/#options) for more information on the optional parameter.\n\nFor a representation consisting only of JSON values, use **`toJSON()`**.\n\nTo stringify a document as YAML, use **`toString(options = {})`**. This will also be called by `String(doc)` (with no options). This method will throw if the `errors` array is not empty. See [Options](https://eemeli.org/yaml/#options) for more information on the optional parameter.\n\n## Stream Directives\n    \n    \n    const doc = new Document()\n    doc.directives\n    > {\n        docStart: null, // set true to force the doc-start marker\n        docEnd: false, // set true to force the doc-end marker\n        tags: { '!!': 'tag:yaml.org,2002:' }, // Record<handle, prefix>\n        yaml: { explicit: false, version: '1.2' }\n      }\n    \n\nA YAML document may be preceded by `%YAML` and `%TAG` directives; their state is accessible via the `directives` member of a `Document`. After parsing or other creation, the contents of `doc.directives` are mutable, and will influence the YAML string representation of the document.\n\nThe contents of `doc.directives.tags` are used both for the `%TAG` directives and when stringifying tags within the document. Each of the handles must start and end with a `!` character; `!` is by default the local tag and `!!` is used for default tags. See the section on [custom tags](https://eemeli.org/yaml/#writing-custom-tags) for more on this topic.\n\n`doc.contents.yaml` determines if an explicit `%YAML` directive should be included in the output, and what version it should use. If changing the version after the document's creation, you'll probably want to use `doc.setSchema()` as it will also update the schema accordingly.\n\n# Content Nodes\n\nAfter parsing, the `contents` value of each `YAML.Document` is the root of an [Abstract Syntax Tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree) of nodes representing the document (or `null` for an empty document).\n\nBoth scalar and collection values may have an `anchor` associated with them; this is rendered in the string representation with a `&` prefix, so e.g. in `foo: &aa bar`, the value `bar` has the anchor `aa`. Anchors are used by [Alias nodes](https://eemeli.org/yaml/#alias-nodes) to allow for the same value to be used in multiple places in the document. It is valid to have an anchor associated with a node even if it has no aliases.\n\n## Scalar Values\n    \n    \n    class NodeBase {\n      comment?: string        // a comment on or immediately after this\n      commentBefore?: string  // a comment before this\n      range?: [number, number, number]\n          // The `[start, value-end, node-end]` character offsets for the part\n          // of the source parsed into this node (undefined if not parsed).\n          // The `value-end` and `node-end` positions are themselves not\n          // included in their respective ranges.\n      spaceBefore?: boolean\n          // a blank line before this node and its commentBefore\n      tag?: string       // a fully qualified tag, if required\n      clone(): NodeBase  // a copy of this node\n      toJS(doc, options?): any // a plain JS representation of this node\n      toJSON(): any      // a plain JSON representation of this node\n    }\n    \n\nFor scalar values, the `tag` will not be set unless it was explicitly defined in the source document; this also applies for unsupported tags that have been resolved using a fallback tag (string, `YAMLMap`, or `YAMLSeq`).\n    \n    \n    class Scalar<T = unknown> extends NodeBase {\n      anchor?: string  // an anchor associated with this node\n      format?: 'BIN' | 'HEX' | 'OCT' | 'TIME' | undefined\n          // By default (undefined), numbers use decimal notation.\n          // The YAML 1.2 core schema only supports 'HEX' and 'OCT'.\n      type?:\n        'BLOCK_FOLDED' | 'BLOCK_LITERAL' | 'PLAIN' |\n        'QUOTE_DOUBLE' | 'QUOTE_SINGLE' | undefined\n      value: T\n    }\n    \n\nA parsed document's contents will have all of its non-object values wrapped in `Scalar` objects, which themselves may be in some hierarchy of `YAMLMap` and `YAMLSeq` collections. However, this is not a requirement for the document's stringification, which is rather tolerant regarding its input values, and will use [`doc.createNode()`](https://eemeli.org/yaml/#creating-nodes) when encountering an unwrapped value.\n\nWhen stringifying, the node `type` will be taken into account by `!!str` and `!!binary` values, and ignored by other scalars. On the other hand, `!!int` and `!!float` stringifiers will take `format` into account.\n\n## Collections\n    \n    \n    class Pair<K = unknown, V = unknown> {\n      key: K    // When parsed, key and value are always\n      value: V  // Node or null, but can be set to anything\n    }\n    \n    class Collection extends NodeBase {\n      anchor?: string  // an anchor associated with this node\n      flow?: boolean   // use flow style when stringifying this\n      schema?: Schema\n      addIn(path: Iterable<unknown>, value: unknown): void\n      clone(schema?: Schema): NodeBase  // a deep copy of this collection\n      deleteIn(path: Iterable<unknown>): boolean\n      getIn(path: Iterable<unknown>, keepScalar?: boolean): unknown\n      hasIn(path: Iterable<unknown>): boolean\n      setIn(path: Iterable<unknown>, value: unknown): void\n    }\n    \n    class YAMLMap<K = unknown, V = unknown> extends Collection {\n      items: Pair<K, V>[]\n      add(pair: Pair<K, V> | { key: K; value: V }, overwrite?: boolean): void\n      delete(key: K): boolean\n      get(key: K, keepScalar?: boolean): unknown\n      has(key: K): boolean\n      set(key: K, value: V): void\n    }\n    \n    class YAMLSeq<T = unknown> extends Collection {\n      items: T[]\n      add(value: T): void\n      delete(key: number | Scalar<number>): boolean\n      get(key: number | Scalar<number>, keepScalar?: boolean): unknown\n      has(key: number | Scalar<number>): boolean\n      set(key: number | Scalar<number>, value: T): void\n    }\n    \n\nWithin all YAML documents, two forms of collections are supported: sequential `YAMLSeq` collections and key-value `YAMLMap` collections. The JavaScript representations of these collections both have an `items` array, which may (`YAMLSeq`) or must (`YAMLMap`) consist of `Pair` objects that contain a `key` and a `value` of any type, including `null`. The `items` array of a `YAMLSeq` object may contain values of any type.\n\nWhen stringifying collections, by default block notation will be used. Flow notation will be selected if `flow` is `true`, the collection is within a surrounding flow collection, or if the collection is in an implicit key.\n\nThe `yaml-1.1` schema includes [additional collections](https://yaml.org/type/index.html) that are based on `YAMLMap` and `YAMLSeq`: `OMap` and `Pairs` are sequences of `Pair` objects (`OMap` requires unique keys & corresponds to the JS Map object), and `Set` is a map of keys with null values that corresponds to the JS Set object.\n\nAll of the collections provide the following accessor methods:\n\nMethod | Returns | Description  \n---|---|---  \nadd(value), addIn(path, value) | `void` | Adds a value to the collection. For `!!map` and `!!omap` the value must be a Pair instance or a `{ key, value }` object, which may not have a key that already exists in the map.  \ndelete(key), deleteIn(path) | `boolean` | Removes a value from the collection. Returns `true` if the item was found and removed.  \nget(key, [keep]), getIn(path, [keep]) | `any` | Returns value at `key`, or `undefined` if not found. By default unwraps scalar values from their surrounding node; to disable set `keep` to `true` (collections are always returned intact).  \nhas(key), hasIn(path) | `boolean` | Checks if the collection includes a value with the key `key`.  \nset(key, value), setIn(path, value) | `any` | Sets a value in this collection. For `!!set`, `value` needs to be a boolean to add/remove the item from the set. When overwriting a `Scalar` value with a scalar, the original node is retained.  \n      \n    \n    const doc = new YAML.Document({ a: 1, b: [2, 3] }) // { a: 1, b: [ 2, 3 ] }\n    doc.add({ key: 'c', value: 4 }) // { a: 1, b: [ 2, 3 ], c: 4 }\n    doc.addIn(['b'], 5)             // { a: 1, b: [ 2, 3, 5 ], c: 4 }\n    doc.set('c', 42)                // { a: 1, b: [ 2, 3, 5 ], c: 42 }\n    doc.setIn(['c', 'x']) // Error: Expected YAML collection at c. Remaining path: x\n    doc.delete('c')                 // { a: 1, b: [ 2, 3, 5 ] }\n    doc.deleteIn(['b', 1])          // { a: 1, b: [ 2, 5 ] }\n    \n    doc.get('a') // 1\n    doc.get('a', true) // Scalar { value: 1 }\n    doc.getIn(['b', 1]) // 5\n    doc.has(doc.createNode('a')) // true\n    doc.has('c') // false\n    doc.hasIn(['b', '0']) // true\n    \n\nFor all of these methods, the keys may be nodes or their wrapped scalar values (i.e. `42` will match `Scalar { value: 42 }`). Keys for `!!seq` should be positive integers, or their string representations. `add()` and `set()` do not automatically call `doc.createNode()` to wrap the value.\n\nEach of the methods also has a variant that requires an iterable as the first parameter, and allows fetching or modifying deeper collections. If any intermediate node in `path` is a scalar rather than a collection, an error will be thrown. If any of the intermediate collections is not found:\n\n  * `getIn` and `hasIn` will return `undefined` or `false` (respectively)\n  * `addIn` and `setIn` will create missing collections; non-negative integer keys will create sequences, all other keys create maps\n  * `deleteIn` will throw an error\n\n\n\nNote that for `addIn` the path argument points to the collection rather than the item; for maps its `value` should be a `Pair` or an object with `{ key, value }` fields.\n\n## Alias Nodes\n    \n    \n    class Alias extends NodeBase {\n      source: string\n      resolve(doc: Document): Scalar | YAMLMap | YAMLSeq | undefined\n    }\n    \n    const obj = YAML.parse('[ &x { X: 42 }, Y, *x ]')\n      // => [ { X: 42 }, 'Y', { X: 42 } ]\n    obj[2].Z = 13\n      // => [ { X: 42, Z: 13 }, 'Y', { X: 42, Z: 13 } ]\n    YAML.stringify(obj)\n      // - &a1\n      //   X: 42\n      //   Z: 13\n      // - Y\n      // - *a1\n    \n\n`Alias` nodes provide a way to include a single node in multiple places in a document; the `source` of an alias node must be a preceding anchor in the document. Circular references are fully supported, and where possible the JS representation of alias nodes will be the actual source object. For ease of use, alias nodes also provide a `resolve(doc)` method to dereference its source node.\n\nWhen nodes are constructed from JS structures (e.g. during `YAML.stringify()`), multiple references to the same object will result in including an autogenerated anchor at its first instance, and alias nodes to that anchor at later references.\n\n## Creating Nodes\n    \n    \n    const doc = new YAML.Document(['some', 'values'])\n    // Document {\n    //   contents:\n    //     YAMLSeq {\n    //       items:\n    //        [ Scalar { value: 'some' },\n    //          Scalar { value: 'values' } ] } }\n    \n    const map = doc.createNode({ balloons: 99 })\n    // YAMLMap {\n    //   items:\n    //    [ Pair {\n    //        key: Scalar { value: 'balloons' },\n    //        value: Scalar { value: 99 } } ] }\n    \n    doc.add(map)\n    doc.get(0, true).comment = ' A commented item'\n    String(doc)\n    // - some # A commented item\n    // - values\n    // - balloons: 99\n    \n\n#### `doc.createNode(value, replacer?, options?): Node`\n\nTo create a new node, use the `createNode(value, options?)` document method. This will recursively wrap any input with appropriate `Node` containers. Generic JS `Object` values as well as `Map` and its descendants become mappings, while arrays and other iterable objects result in sequences. With `Object`, entries that have an `undefined` value are dropped.\n\nIf `value` is already a `Node` instance, it will be directly returned. To create a copy of a node, use instead the `node.clone()` method. For collections, the method accepts a single `Schema` argument, which allows overwriting the original's `schema` value.\n\nUse a `replacer` to apply a replacer array or function, following the [JSON implementation](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#The_replacer_parameter). To force flow styling on a collection, use the `flow: true` option. For all available options, see the [CreateNode Options](https://eemeli.org/yaml/#createnode-options) section.\n\nThe primary purpose of this method is to enable attaching comments or other metadata to a value, or to otherwise exert more fine-grained control over the stringified output. To that end, you'll need to assign its return value to the `contents` of a document (or somewhere within said contents), as the document's schema is required for YAML string output. If you're not interested in working with such metadata, document `contents` may also include non-`Node` values at any level.\n\n#### `doc.createAlias(node, name?): Alias`\n    \n    \n    const alias = doc.createAlias(doc.get(1, true), 'foo')\n    doc.add(alias)\n    String(doc)\n    // - some # A commented item\n    // - &foo values\n    // - balloons: 99\n    // - *foo\n    \n\nCreate a new `Alias` node, ensuring that the target `node` has the required anchor. If `node` already has an anchor, `name` is ignored. Otherwise, the `node.anchor` value will be set to `name`, or if an anchor with that name is already present in the document, `name` will be used as a prefix for a new unique anchor. If `name` is undefined, the generated anchor will use 'a' as a prefix.\n\nYou should make sure to only add alias nodes to the document after the nodes to which they refer, or the document's YAML stringification will fail.\n\n#### `new YAMLMap(), new YAMLSeq(), doc.createPair(key, value): Pair`\n    \n    \n    import { Document, YAMLSeq } from 'yaml'\n    \n    const doc = new Document(new YAMLSeq())\n    doc.contents.items = [\n      'some values',\n      42,\n      { including: 'objects', 3: 'a string' }\n    ]\n    doc.add(doc.createPair(1, 'a number'))\n    \n    doc.toString()\n    // - some values\n    // - 42\n    // - \"3\": a string\n    //   including: objects\n    // - 1: a number\n    \n\nTo construct a `YAMLSeq` or `YAMLMap`, use `new Document()` or `doc.createNode()` with array, object or iterable input, or create the collections directly by importing the classes from `yaml`.\n\nOnce created, normal array operations may be used to modify the `items` array. New `Pair` objects may created either by importing the class from `yaml` and using its `new Pair(key, value)` constructor, or by using the `doc.createPair(key, value, options?)` method. The latter will recursively wrap the `key` and `value` as nodes, and accepts the same options as `doc.createNode()`\n\n## Finding and Modifying Nodes\n    \n    \n    const doc = YAML.parseDocument(`\n      - some values\n      - 42\n      - \"3\": a string\n        including: objects\n      - 1: a number\n    `)\n    \n    const obs = doc.getIn([2, 'including'], true)\n    obs.type = 'QUOTE_DOUBLE'\n    \n    YAML.visit(doc, {\n      Pair(_, pair) {\n        if (pair.key && pair.key.value === '3') return YAML.visit.REMOVE\n      },\n      Scalar(key, node) {\n        if (\n          key !== 'key' &&\n          typeof node.value === 'string' &&\n          node.type === 'PLAIN'\n        ) {\n          node.type = 'QUOTE_SINGLE'\n        }\n      }\n    })\n    \n    String(doc)\n    // - 'some values'\n    // - 42\n    // - including: \"objects\"\n    // - 1: 'a number'\n    \n\nIn general, it's safe to modify nodes manually, e.g. splicing the `items` array of a `YAMLMap` or setting its `flow` value to `true`. For operations on nodes at a known location in the tree, it's probably easiest to use `doc.getIn(path, true)` to access them. For more complex or general operations, a visitor API is provided:\n\n#### `YAML.visit(node, visitor): void`\n\nApply a visitor to an AST node or document.\n\nWalks through the tree (depth-first) starting from `node`, calling a `visitor` function with three arguments:\n\n  * `key`: For sequence values and map `Pair`, the node's index in the collection. Within a `Pair`, `'key'` or `'value'`, correspondingly. `null` for the root node.\n  * `node`: The current node.\n  * `path`: The ancestry of the current node.\n\n\n\nThe return value of the visitor may be used to control the traversal:\n\n  * `undefined` (default): Do nothing and continue\n  * `YAML.visit.SKIP`: Do not visit the children of this node, continue with next sibling\n  * `YAML.visit.BREAK`: Terminate traversal completely\n  * `YAML.visit.REMOVE`: Remove the current node, then continue with the next one\n  * `Node`: Replace the current node, then continue by visiting it\n  * `number`: While iterating the items of a sequence or map, set the index of the next step. This is useful especially if the index of the current node has changed.\n\n\n\nIf `visitor` is a single function, it will be called with all values encountered in the tree, including e.g. `null` values. Alternatively, separate visitor functions may be defined for each `Map`, `Pair`, `Seq`, `Alias` and `Scalar` node. To define the same visitor function for more than one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar) and `Node` (alias, map, seq & scalar) targets. Of all these, only the most specific defined one will be used for each node.\n\n#### `YAML.visitAsync(node, visitor): Promise<void>`\n\nThe same as `visit()`, but allows for visitor functions that return a promise which resolves to one of the above-defined control values.\n\n## Identifying Node Types\n    \n    \n    import {\n      isAlias,\n      isCollection, // map or seq\n      isDocument,\n      isMap,\n      isNode, // alias, scalar, map or seq\n      isPair,\n      isScalar,\n      isSeq\n    } from 'yaml'\n    \n    const doc = new Document({ foo: [13, 42] })\n    isDocument(doc) === true\n    isNode(doc) === false\n    isMap(doc.contents) === true\n    isNode(doc.contents) === true\n    isPair(doc.contents.items[0]) === true\n    isCollection(doc.get('foo')) === true\n    isScalar(doc.getIn(['foo', 1])) === true\n    \n\n#### `isAlias(x: unknown): boolean`\n\n#### `isCollection(x: unknown): boolean`\n\n#### `isDocument(x: unknown): boolean`\n\n#### `isMap(x: unknown): boolean`\n\n#### `isNode(x: unknown): boolean`\n\n#### `isPair(x: unknown): boolean`\n\n#### `isScalar(x: unknown): boolean`\n\n#### `isSeq(x: unknown): boolean`\n\nTo find out what you've got, a family of custom type guard functions is provided. These should be preferred over other methods such as `instanceof` checks, as they'll work even if the nodes have been created by a different instance of the library.\n\nInternally, node identification uses property symbols that are set on instances during their construction.\n\n## Comments and Blank Lines\n    \n    \n    const doc = YAML.parseDocument(`\n    # This is YAML.\n    ---\n    it has:\n    \n      - an array\n    \n      - of values\n    `)\n    \n    doc.toJS() // { 'it has': [ 'an array', 'of values' ] }\n    doc.commentBefore // ' This is YAML.'\n    \n    const seq = doc.get('it has')\n    seq.spaceBefore // true\n    \n    seq.items[0].comment = ' item comment'\n    seq.comment = ' collection end comment'\n    \n    doc.toString()\n    // # This is YAML.\n    //\n    // it has:\n    //\n    //   - an array # item comment\n    //\n    //   - of values\n    //   # collection end comment\n    \n\nA primary differentiator between this and other YAML libraries is the ability to programmatically handle comments, which according to [the spec](http://yaml.org/spec/1.2/spec.html#id2767100) \"must not have any effect on the serialization tree or representation graph. In particular, comments are not associated with a particular node.\" Similarly to comments, the YAML spec instructs non-content blank lines to be discarded.\n\nThis library _does_ allow comments and blank lines to be handled programmatically, and does attach them to particular nodes (most often, the following node). Each `Scalar`, `Map`, `Seq` and the `Document` itself has `comment`, `commentBefore` members that may be set to a stringifiable value, and a `spaceBefore` boolean to add an empty line before the comment.\n\nThe string contents of comments are not processed by the library, except for merging adjacent comment and blank lines together. Document comments will be separated from the rest of the document by a blank line. In the node member values, comment lines terminating with the `#` indicator are represented by a single space, while completely empty lines are represented as empty strings.\n\nScalar block values with \"keep\" chomping (i.e. with `+` in their header) consider any trailing empty lines to be a part of their content, so the following node's `spaceBefore` or `commentBefore` with leading whitespace is ignored.\n\n**Note** : Due to implementation details, the library's comment handling is not completely stable, in particular for trailing comments. When creating, writing, and then reading a YAML file, comments may sometimes be associated with a different node.\n\n# Custom Data Types\n    \n    \n    import { parse, parseDocument } from 'yaml'\n    \n    parse('2001-12-15 2:59:43')\n    // '2001-12-15 2:59:43'\n    \n    parse('!!timestamp 2001-12-15 2:59:43')\n    // 2001-12-15T02:59:43.000Z (Date instance)\n    \n    const doc = parseDocument('2001-12-15 2:59:43', { customTags: ['timestamp'] })\n    doc.contents.value.toDateString()\n    // 'Sat Dec 15 2001'\n    \n\nThe easiest way to extend a [schema](https://eemeli.org/yaml/#data-schemas) is by defining the additional **tags** that you wish to support. To do that, the `customTags` option allows you to provide an array of custom tag objects or tag identifiers. In particular, the built-in tags that are a part of the `core` and `yaml-1.1` schemas may be referred to by their string identifiers. For those tags that are available in both, only the `core` variant is provided as a custom tag.\n\nFor further customisation, `customTags` may also be a function `(Tag[]) => (Tag[])` that may modify the schema's base tag array.\n\nSome additional data types are available separately via the [`yaml-types`](https://github.com/eemeli/yaml-types) package, including support for:\n\n  * BigInt values\n  * Error objects\n  * Objects with a null prototype\n  * RegExp values\n  * Symbols\n\n\n\n## Built-in Custom Tags\n    \n    \n    parse('[ one, true, 42 ]')\n    // [ 'one', true, 42 ]\n    \n    parse('[ one, true, 42 ]', { schema: 'failsafe' })\n    // [ 'one', 'true', '42' ]\n    \n    parse('[ one, true, 42 ]', { schema: 'failsafe', customTags: ['int'] })\n    // [ 'one', 'true', 42 ]\n    \n\n### YAML 1.2 Core Schema\n\nThese tags are a part of the YAML 1.2 [Core Schema](https://yaml.org/spec/1.2/spec.html#id2804923), and may be useful when constructing a parser or stringifier for a more limited set of types, based on the `failsafe` schema. Some of these define a `format` value; this will be added to the parsed nodes and affects the node's stringification.\n\nIf including more than one custom tag from this set, make sure that the `'float'` and `'int'` tags precede any of the other `!!float` and `!!int` tags.\n\nIdentifier | Regular expression | YAML Type | Format | Example values  \n---|---|---|---|---  \n`'bool'` | `trueâŽ®TrueâŽ®TRUEâŽ®falseâŽ®FalseâŽ®FALSE` | `!!bool` |  | `true`, `false`  \n`'float'` | `[-+]?(0âŽ®[1-9][0-9]*)\\.[0-9]*` | `!!float` |  | `4.2`, `-0.0`  \n`'floatExp'` | `[-+]?(0âŽ®[1-9][0-9]*)(\\.[0-9]*)?[eE][-+]?[0-9]+` | `!!float` | `'EXP'` | `4.2e9`  \n`'floatNaN'` | `[-+]?(\\.infâŽ®\\.InfâŽ®\\.INF)âŽ®\\.nanâŽ®\\.NaNâŽ®\\.NAN` | `!!float` |  | `-Infinity`  \n`'int'` | `[-+]?[0-9]+` | `!!int` |  | `42`, `-0`  \n`'intHex'` | `0x[0-9a-fA-F]+` | `!!int` | `'HEX'` | `0xff0033`  \n`'intOct'` | `0o[0-7]+` | `!!int` | `'OCT'` | `0o127`  \n`'null'` | `~âŽ®nullâŽ®NullâŽ®NULL` | `!!null` |  | `null`  \n  \n### YAML 1.1\n\nThese tags are a part of the YAML 1.1 [language-independent types](https://yaml.org/type/), but are not a part of any default YAML 1.2 schema.\n\nIdentifier | YAML Type | JS Type | Description  \n---|---|---|---  \n`'binary'` | [`!!binary`](https://yaml.org/type/binary.html) | `Uint8Array` | Binary data, represented in YAML as base64 encoded characters.  \n`'floatTime'` | [`!!float`](https://yaml.org/type/float.html) | `Number` | Sexagesimal floating-point number format, e.g. `190:20:30.15`. To stringify with this tag, the node `format` must be `'TIME'`.  \n`'intTime'` | [`!!int`](https://yaml.org/type/int.html) | `Number` | Sexagesimal integer number format, e.g. `190:20:30`. To stringify with this tag, the node `format` must be `'TIME'`.  \n`'merge'` | [`!!merge`](https://yaml.org/type/merge.html) | `Symbol('<<')` | A `<<` merge key which allows one or more mappings to be merged with the current one.  \n`'omap'` | [`!!omap`](https://yaml.org/type/omap.html) | `Map` | Ordered sequence of key: value pairs without duplicates. Using `mapAsMap: true` together with this tag is not recommended, as it makes the parse â†’ stringify loop non-idempotent.  \n`'pairs'` | [`!!pairs`](https://yaml.org/type/pairs.html) | `Array` | Ordered sequence of key: value pairs allowing duplicates. To create from JS, use `doc.createNode(array, { tag: '!!pairs' })`.  \n`'set'` | [`!!set`](https://yaml.org/type/set.html) | `Set` | Unordered set of non-equal values.  \n`'timestamp'` | [`!!timestamp`](https://yaml.org/type/timestamp.html) | `Date` | A point in time, e.g. `2001-12-15T02:59:43`.  \n  \n## Writing Custom Tags\n    \n    \n    import { YAMLMap, stringify } from 'yaml'\n    import { stringifyString } from 'yaml/util'\n    \n    const regexp = {\n      identify: value => value instanceof RegExp,\n      tag: '!re',\n      resolve(str) {\n        const match = str.match(/^\\/([\\s\\S]+)\\/([gimuy]*)$/)\n        if (!match) throw new Error('Invalid !re value')\n        return new RegExp(match[1], match[2])\n      }\n    }\n    \n    const sharedSymbol = {\n      identify: value => value?.constructor === Symbol,\n      tag: '!symbol/shared',\n      resolve: str => Symbol.for(str),\n      stringify(item, ctx, onComment, onChompKeep) {\n        const key = Symbol.keyFor(item.value)\n        if (key === undefined) throw new Error('Only shared symbols are supported')\n        return stringifyString({ value: key }, ctx, onComment, onChompKeep)\n      }\n    }\n    \n    class YAMLNullObject extends YAMLMap {\n      tag = '!nullobject'\n      toJSON(_, ctx) {\n        const obj = super.toJSON(_, { ...ctx, mapAsMap: false }, Object)\n        return Object.assign(Object.create(null), obj)\n      }\n    }\n    \n    const nullObject = {\n      tag: '!nullobject',\n      collection: 'map',\n      nodeClass: YAMLNullObject,\n      identify: v => !!(typeof v === 'object' && v && !Object.getPrototypeOf(v))\n    }\n    \n    // slightly more complicated object type\n    class YAMLError extends YAMLMap {\n      tag = '!error'\n      toJSON(_, ctx) {\n        const { name, message, stack, ...rest } = super.toJSON(\n          _,\n          { ...ctx, mapAsMap: false },\n          Object\n        )\n        // craft the appropriate error type\n        const Cls =\n          name === 'EvalError'\n            ? EvalError\n            : name === 'RangeError'\n              ? RangeError\n              : name === 'ReferenceError'\n                ? ReferenceError\n                : name === 'SyntaxError'\n                  ? SyntaxError\n                  : name === 'TypeError'\n                    ? TypeError\n                    : name === 'URIError'\n                      ? URIError\n                      : Error\n        if (Cls.name !== name) {\n          Object.defineProperty(er, 'name', {\n            value: name,\n            enumerable: false,\n            configurable: true\n          })\n        }\n        Object.defineProperty(er, 'stack', {\n          value: stack,\n          enumerable: false,\n          configurable: true\n        })\n        return Object.assign(er, rest)\n      }\n    \n      static from(schema, obj, ctx) {\n        const { name, message, stack } = obj\n        // ensure these props remain, even if not enumerable\n        return super.from(schema, { ...obj, name, message, stack }, ctx)\n      }\n    }\n    \n    const error = {\n      tag: '!error',\n      collection: 'map',\n      nodeClass: YAMLError,\n      identify: v => !!(typeof v === 'object' && v && v instanceof Error)\n    }\n    \n    stringify(\n      {\n        regexp: /foo/gi,\n        symbol: Symbol.for('bar'),\n        nullobj: Object.assign(Object.create(null), { a: 1, b: 2 }),\n        error: new Error('This was an error')\n      },\n      { customTags: [regexp, sharedSymbol, nullObject, error] }\n    )\n    // regexp: !re /foo/gi\n    // symbol: !symbol/shared bar\n    // nullobj: !nullobject\n    //   a: 1\n    //   b: 2\n    // error: !error\n    //   name: Error\n    //   message: 'This was an error'\n    //   stack: |\n    //     at some-file.js:1:3\n    \n\nIn YAML-speak, a custom data type is represented by a _tag_. To define your own tag, you need to account for the ways that your data is both parsed and stringified. Furthermore, both of those processes are split into two stages by the intermediate AST node structure.\n\nIf you wish to implement your own custom tags, the [`!!binary`](https://github.com/eemeli/yaml/blob/main/src/schema/yaml-1.1/binary.ts) and [`!!set`](https://github.com/eemeli/yaml/blob/main/src/schema/yaml-1.1/set.ts) tags as well as the [`yaml-types`](https://github.com/eemeli/yaml-types) package provide relatively cohesive examples to study in addition to the simple examples in the sidebar here.\n\nCustom collection types (ie, Maps, Sets, objects, and arrays; anything with child properties that may not be propertly serialized to a scalar value) may provide a `nodeClass` property that extends the [`YAMLMap`](https://github.com/eemeli/yaml/blob/main/src/nodes/YAMLMap.ts) and [`YAMLSeq`](https://github.com/eemeli/yaml/blob/main/src/nodes/YAMLSeq.ts) classes, which will be used for parsing and stringifying objects with the specified tag.\n\n### Parsing Custom Data\n\nAt the lowest level, the [`Lexer`](https://eemeli.org/yaml/#lexer) and [`Parser`](https://eemeli.org/yaml/#parser) will take care of turning string input into a concrete syntax tree (CST). In the CST all scalar values are available as strings, and maps & sequences as collections of nodes. Each schema includes a set of default data types, which handle converting at least strings, maps and sequences into their AST nodes. These are considered to have _implicit_ tags, and are autodetected. Custom tags, on the other hand, should almost always define an _explicit_ `tag` with which their value will be prefixed. This may be application-specific local `!tag`, a shorthand `!ns!tag`, or a verbatim `!<tag:example.com,2019:tag>`.\n\nOnce identified by matching the `tag`, the `resolve(value, onError): Node | any` function will turn a parsed value into an AST node. `value` may be either a `string`, a `YAMLMap` or a `YAMLSeq`, depending on the node's shape. A custom tag should verify that value is of its expected type.\n\nNote that during the CST -> AST composition, the anchors and comments attached to each node are also resolved for each node. This metadata will unfortunately be lost when converting the values to JS objects, so collections should have values that extend one of the existing collection classes. Collections should therefore either fall back to their parent classes' `toJSON()` methods, or define their own in order to allow their contents to be expressed as the appropriate JS object.\n\n### Creating Nodes and Stringifying Custom Data\n\nAs with parsing, turning input data into its YAML string representation is a two-stage process as the input is first turned into an AST tree before stringifying it. This allows for metadata and comments to be attached to each node, and for e.g. circular references to be resolved. For scalar values, this means just wrapping the value within a `Scalar` class while keeping it unchanged.\n\nAs values may be wrapped within objects and arrays, `doc.createNode()` uses each tag's `identify(value): boolean` function to detect custom data types. For the same reason, collections need to define their own `createNode(schema, value, ctx): Collection` functions that may recursively construct their equivalent collection class instances.\n\nFinally, `stringify(item, ctx, ...): string` defines how your data should be represented as a YAML string, in case the default stringifiers aren't enough. For collections in particular, the default stringifier should be perfectly sufficient. `'yaml/util'` exports `stringifyNumber(item)` and `stringifyString(item, ctx, ...)`, which may be of use for custom scalar data.\n\n### Custom Tag API\n    \n    \n    import {\n      createNode, // (value, tagName, ctx) => Node -- Create a new node\n      createPair, // (key, value, ctx) => Pair -- Create a new pair\n      debug, // (logLevel, ...messages) => void -- Log debug messages to console\n      findPair, // (items, key) => Pair? -- Given a key, find a matching Pair\n      foldFlowLines, // (text, indent, mode, options) => string -- Fold long lines\n      mapTag, // CollectionTag\n      seqTag, // CollectionTag\n      stringTag, // ScalarTag\n      stringifyNumber, // (node) => string\n      stringifyString, // (node, ctx, ...) => string\n      toJS, // (value, arg, ctx) => any -- Recursively convert to plain JS\n      warn // (logLevel, warning) => void -- Emit a warning\n    } from 'yaml/util'\n    \n\nTo define your own tag, you'll need to define an object comprising of some of the following fields. Those in bold are required:\n\n  * `createNode(schema, value, ctx): Node` is an optional factory function, used e.g. by collections when wrapping JS objects as AST nodes.\n  * `format: string` If a tag has multiple forms that should be parsed and/or stringified differently, use `format` to identify them. Used by `!!int` and `!!float`.\n  * **`identify(value): boolean`** is used by `doc.createNode()` to detect your data type, e.g. using `typeof` or `instanceof`. Required.\n  * `nodeClass: Node` is the `Node` child class that implements this tag. Required for collections and tags that have overlapping JS representations.\n  * **`resolve(value, onError): Node | any`** turns a parsed value into an AST node; `value` is either a `string`, a `YAMLMap` or a `YAMLSeq`. `onError(msg)` should be called with an error message string when encountering errors, as it'll allow you to still return some value for the node. If returning a non-`Node` value, the output will be wrapped as a `Scalar`. Required.\n  * `stringify(item, ctx, onComment, onChompKeep): string` is an optional function stringifying the `item` AST node in the current context `ctx`. `onComment` and `onChompKeep` are callback functions for a couple of special cases. If your data includes a suitable `.toString()` method, you can probably leave this undefined and use the default stringifier.\n  * **`tag: string`** is the identifier for your data type, with which its stringified form will be prefixed. Should either be a !-prefixed local `!tag`, or a fully qualified `tag:domain,date:foo`. Required.\n  * `test: RegExp` and `default: boolean` allow for values to be stringified without an explicit tag and detected using a regular expression. For most cases, it's unlikely that you'll actually want to use these, even if you first think you do.\n\n\n\n# Parsing YAML\n    \n    \n    import {\n      Composer,\n      CST,\n      Lexer,\n      LineCounter,\n      Parser,\n    } from 'yaml'\n    \n\nIf you're interested only in the final output, [`parse()`](https://eemeli.org/yaml/#yaml-parse) will directly produce native JavaScript If you'd like to retain the comments and other metadata, [`parseDocument()` and `parseAllDocuments()`](https://eemeli.org/yaml/#parsing-documents) will produce Document instances that allow for further processing. If you're looking to do something more specific, this section might be for you.\n\nInternally, the process of turning a sequence of characters into Documents relies on three stages, each of which is also exposed to external users. First, the [Lexer](https://eemeli.org/yaml/#lexer) splits the character stream into lexical tokens, i.e. sequences of characters and control codes. Next, the [Parser](https://eemeli.org/yaml/#parser) builds concrete syntax tree representations of each document and directive in the stream. Finally, the [Composer](https://eemeli.org/yaml/#composer) builds a more user-friendly and accessible [Document](https://eemeli.org/yaml/#documents) representation of each document.\n\nBoth the Lexer and Parser accept incomplete input, allowing for them and the Composer to be used with e.g. [Node.js streams](https://nodejs.org/api/stream.html) or other systems that handle data in chunks.\n\n## Lexer\n    \n    \n    import { Lexer } from 'yaml'\n    \n    const tokens = new Lexer().lex('foo: bar\\nfee:\\n  [24,\"42\"]\\n')\n    console.dir(Array.from(tokens))\n    > [\n        '\\x02', '\\x1F', 'foo',  ':',\n        '',    '\\x1F', 'bar',  '\\n',\n        '\\x1F', 'fee',  ':',    '\\n',\n        '',   '[',    '\\x1F', '24',\n        ',',    '\"42\"', ']',    '\\n'\n      ]\n    \n\n#### `new Lexer()`\n\n#### `lexer.lex(src: string, incomplete?: boolean): Generator<string>`\n\nThe API for the lexer is rather minimal, and offers no configuration. If the input stream is chunked, the `lex()` method may be called separately for each chunk if the `incomplete` argument is `true`. At the end of input, `lex()` should be called a final time with `incomplete: false` to ensure that the remaining tokens are emitted.\n\nInternally, the lexer operates a state machine that determines how it parses its input. Initially, the lexer is always in the `stream` state. The lexer constructor and its `lex()` method should never throw an error.\n\nAll tokens are identifiable either by their exact value or their first character. In addition to slices of the input stream, a few control characters are additionally used within the output.\n\nValue | Token | Meaning  \n---|---|---  \n`\\x02` | doc-mode | Start of a document within the default stream context.  \n`\\x18` | flow-error-end | Unexpected end of a flow collection, e.g. due to an unindent. Should be considered an error.  \n`\\x1f` | scalar | The next token after this one is a scalar value, irrespective of its value or first character.  \n`\\n`, `\\r\\n` | newline | In certain cases (such as end of input), an empty string may also be emitted; it should also be considered as a newline.  \n`---` | doc-start | Explicit marker for the start of a document. Will be preceded by a doc-mode token.  \n`...` | doc-end | Explicit marker for the end of a document.  \n`-` | seq-item-ind | Block sequence item indicator, separated by whitespace.  \n`?` | explicit-key-ind | Explicit block map key indicator, separated by whitespace.  \n`:` | map-value-ind | Block map value indicator.  \n`{` | flow-map-start |   \n`}` | flow-map-end |   \n`[` | flow-seq-start |   \n`]` | flow-seq-end |   \n`,` | comma | Separator between flow collection items.  \n`\\u{FEFF}` | byte-order-mark | Treated as whitespace in stream & content in a document.  \n  \nIf any of the control characters do show up directly in the input stream, they will be treated normally, and even when bare will be preceded by a SCALAR control token in the output.\n\nAll remaining tokens are identifiable by their first character:\n\nFirst char | Token | Meaning  \n---|---|---  \n``, `\\t` | space | Only contains space characters if token indicates indentation. Otherwise may contain repeats of either character.  \n`#` | comment | Separated from preceding by whitespace. Does not include the trailing newline.  \n`%` | directive-line | Only produced in a stream context.  \n`*` | alias |   \n`&` | anchor |   \n`!` | tag |   \n`'` | single-quoted-scalar | Should also include `'` as a last character, if input is valid.  \n`\"` | double-quoted-scalar | Should also include `\"` as a last character, if input is valid.  \n`âŽ®`, `>` | block-scalar-header | Expected to be followed by optional whitespace & comment, a newline, and then a scalar value.  \n  \n## Parser\n    \n    \n    import { Parser } from 'yaml'\n    \n    for (const token of new Parser().parse('foo: [24,\"42\"]\\n'))\n      console.dir(token, { depth: null })\n    \n    > {\n        type: 'document',\n        offset: 0,\n        start: [],\n        value: {\n          type: 'block-map',\n          offset: 0,\n          indent: 0,\n          items: [\n            {\n              start: [],\n              key: { type: 'scalar', offset: 0, indent: 0, source: 'foo' },\n              sep: [\n                { type: 'map-value-ind', offset: 3, indent: 0, source: ':' },\n                { type: 'space', offset: 4, indent: 0, source: '' }\n              ],\n              value: {\n                type: 'flow-collection',\n                offset: 5,\n                indent: 0,\n                start: { type: 'flow-seq-start', offset: 5, indent: 0, source: '[' },\n                items: [\n                  { type: 'scalar', offset: 6, indent: 0, source: '24' },\n                  { type: 'comma', offset: 8, indent: 0, source: ',' },\n                  {\n                    type: 'double-quoted-scalar',\n                    offset: 9,\n                    indent: 0,\n                    source: '\"42\"'\n                  }\n                ],\n                end: [\n                  { type: 'flow-seq-end', offset: 13, indent: 0, source: ']' },\n                  { type: 'newline', offset: 14, indent: 0, source: '\\n' }\n                ]\n              }\n            }\n          ]\n        }\n      }\n    \n\nThe parser by default uses an internal Lexer instance, and provides a similarly minimal API for producing a [Concrete Syntax Tree](https://en.wikipedia.org/wiki/Concrete_syntax_tree) representation of the input stream.\n\nThe tokens emitted by the parser are JavaScript objects, each of which has a `type` value that's one of the following: `directive-line`, `document`, `byte-order-mark`, `space`, `comment`, `newline`. Of these, only `directive-line` and `document` should be considered as content.\n\nThe parser does not validate its output, trying instead to produce a most YAML-ish representation of any input. It should never throw errors, but may (rarely) include error tokens in its output.\n\nTo validate a CST, you will need to compose it into a `Document`. If the document contains errors, they will be included in the document's `errors` array, and each error will will contain an `offset` within the source string, which you may then use to find the corresponding node in the CST.\n\n#### `new Parser(onNewLine?: (offset: number) => void)`\n\nCreate a new parser. If defined, `onNewLine` is called separately with the start position of each new line (in `parse()`, including the start of input).\n\n#### `parser.parse(source: string, incomplete = false): Generator<Token, void>`\n\nParse `source` as a YAML stream, generating tokens for each directive, document and other structure as it is completely parsed. If `incomplete`, a part of the last line may be left as a buffer for the next call.\n\nErrors are not thrown, but are yielded as `{ type: 'error', offset, message }` tokens.\n\n#### `parser.next(lexToken: string): Generator<Token, void>`\n\nAdvance the parser by one lexical token. Used internally by `parser.parse()`; exposed to allow for use with an external lexer.\n\nFor debug purposes, if the `LOG_TOKENS` env var is true-ish, all lexical tokens will be pretty-printed using `console.log()` as they are being processed.\n\n### CST Nodes\n\nFor a complete description of CST node interfaces, please consult the [cst.ts source](https://github.com/eemeli/yaml/blob/main/src/parse/cst.ts).\n\nSome of the most common node properties include:\n\nProperty | Type | Description  \n---|---|---  \n`type` | `string` | The only node property that's always defined. Identifies the node type. May be used as a TS type guard.  \n`offset` | `number` | The start index within the source string or character stream.  \n`source` | `string` | A raw string representation of the node's value, including all newlines and indentation.  \n`indent` | `number` | The indent level of the current line; mostly just for internal use.  \n`items` | `Item[]` | The contents of a collection; exact shape depends on the collection type.  \n`start`, `sep`, `end` | `SourceToken[]` | Content before, within, and after \"actual\" values. Includes item and collection indicators, anchors, tags, comments, as well as other things.  \n  \nCollection items contain some subset of the following properties:\n\nItem property | Type | Description  \n---|---|---  \n`start` | `SourceToken[]` | Always defined. Content before the actual value. May include comments that are later assigned to the preceding item.  \n`key` | `Token âŽ® null` | Set for key/value pairs only, so never used in block sequences.  \n`sep` | `SourceToken[]` | Content between the key and the value. If defined, indicates that the `key` logically exists, even if its value is `null`.  \n`value` | `Token âŽ® null` | The value. Normally set, but may be left out for e.g. explicit keys with no matching value.  \n  \n### Counting Lines\n    \n    \n    import { LineCounter, Parser } from 'yaml'\n    \n    const lineCounter = new LineCounter()\n    const parser = new Parser(lineCounter.addNewLine))\n    const tokens = parser.parse('foo:\\n- 24\\n- \"42\"\\n')\n    Array.from(tokens) // forces iteration\n    \n    lineCounter.lineStarts\n    > [ 0, 5, 10, 17 ]\n    lineCounter.linePos(3)\n    > { line: 1, col: 4 }\n    lineCounter.linePos(5)\n    > { line: 2, col: 1 }\n    \n\n#### `new LineCounter()`\n\nTracks newlines during parsing in order to provide an efficient API for determining the one-indexed `{ line, col }` position for any offset within the input.\n\n#### `lineCounter.addNewLine(offset: number)`\n\nAdds the starting index of a new line. Should be called in order, or the internal `lineStarts` array will need to be sorted before calling `linePos()`. Bound to the instance, so may be used directly as a callback.\n\n#### `lineCounter.linePos(offset: number): { line: number, col: number }`\n\nPerforms a binary search and returns the 1-indexed `{ line, col }` position of `offset`. If `line === 0`, `addNewLine` has never been called or `offset` is before the first known newline.\n\n## Composer\n    \n    \n    import { Composer, Parser } from 'yaml'\n    \n    const src = 'foo: bar\\nfee: [24, \"42\"]'\n    const tokens = new Parser().parse(src)\n    const docs = new Composer().compose(tokens)\n    \n    Array.from(docs, doc => doc.toJS())\n    > [{ foo: 'bar', fee: [24, '42'] }]\n    \n\n#### `new Composer(options?: ParseOptions & DocumentOptions & SchemaOptions)`\n\nCreate a new Document composer. Does not include an internal Parser instance, so an external one will be needed. `options` will be used during composition, and passed to the `new Document` constructor.\n\n#### `composer.compose(tokens: Iterable<Token>, forceDoc?: boolean, endOffset?: number): Generator<Document.Parsed>`\n\nCompose tokens into documents. Convenience wrapper combining calls to `composer.next()` and `composer.end()`.\n\n#### `composer.next(token: Token): Generator<Document.Parsed>`\n\nAdvance the composed by one CST token.\n\n#### `composer.end(forceDoc?: boolean, offset?: number): Generator<Document.Parsed>`\n\nAlways call at end of input to push out any remaining document. If `forceDoc` is true and the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document. `offset` should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.\n\n#### `composer.streamInfo(): { comment, directives, errors, warnings }`\n\nCurrent stream status information. Mostly useful at the end of input for an empty stream.\n\n## Working with CST Tokens\n    \n    \n    import { CST } from 'yaml'\n    \n\nFor most use cases, the Document or pure JS interfaces provided by the library are the right tool. Sometimes, though, it's important to keep the original YAML source in as pristine a condition as possible. For those cases, the concrete syntax tree (CST) representation is provided, as it retains every character of the input, including whitespace.\n\n#### `CST.createScalarToken(value: string, context): BlockScalar | FlowScalar`\n\nCreate a new scalar token with the value `value`. Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`, as this function does not support any schema operations and won't check for such conflicts.\n\nArgument | Type | Default | Description  \n---|---|---|---  \nvalue | `string` |  | The string representation of the value, which will have its content properly indented. **Required.**  \ncontext.end | `SourceToken[]` |  | Comments and whitespace after the end of the value, or after the block scalar header. If undefined, a newline will be added.  \ncontext.implicitKey | `boolean` | `false` | Being within an implicit key may affect the resolved type of the token's value.  \ncontext.indent | `number` |  | The indent level of the token. **Required.**  \ncontext.inFlow | `boolean` | `false` | Is this scalar within a flow collection? This may affect the resolved type of the token's value.  \ncontext.offset | `number` | `-1` | The offset position of the token.  \ncontext.type | `Scalar.Type` |  | The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.  \n      \n    \n    const [doc] = new Parser().parse('foo: \"bar\" #comment')\n    const item = doc.value.items[0].value\n    > {\n        type: 'double-quoted-scalar',\n        offset: 5,\n        indent: 0,\n        source: '\"bar\"',\n        end: [\n          { type: 'space', offset: 10, indent: 0, source: '' },\n          { type: 'comment', offset: 11, indent: 0, source: '#comment' }\n        ]\n      }\n    \n    CST.resolveAsScalar(item)\n    > { value: 'bar', type: 'QUOTE_DOUBLE', comment: 'comment', range: [5, 9, 19] }\n    \n\n#### `CST.isCollection(token?: Token): boolean`\n\n#### `CST.isScalar(token?: Token): boolean`\n\nCustom type guards for detecting CST collections and scalars, in both their block and flow forms.\n\n#### `CST.resolveAsScalar(token?: Token, strict = true, onError?: ComposeErrorHandler)`\n\nIf `token` is a CST flow or block scalar, determine its string value and a few other attributes. Otherwise, return `null`.\n\n#### `CST.setScalarValue(token: Token, value: string, context?)`\n\nSet the value of `token` to the given string `value`, overwriting any previous contents and type that it may have.\n\nBest efforts are made to retain any comments previously associated with the `token`, though all contents within a collection's `items` will be overwritten.\n\nValues that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`, as this function does not support any schema operations and won't check for such conflicts.\n\nArgument | Type | Default | Description  \n---|---|---|---  \ntoken | `Token` |  | Any token. If it does not include an `indent` value, the value will be stringified as if it were an implicit key. **Required.**  \nvalue | `string` |  | The string representation of the value, which will have its content properly indented. **Required.**  \ncontext.afterKey | `boolean` | `false` | In most cases, values after a key should have an additional level of indentation.  \ncontext.implicitKey | `boolean` | `false` | Being within an implicit key may affect the resolved type of the token's value.  \ncontext.inFlow | `boolean` | `false` | Being within a flow collection may affect the resolved type of the token's value.  \ncontext.type | `Scalar.Type` |  | The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.  \n      \n    \n    function findScalarAtOffset(\n      cst: CST.Document,\n      offset: number\n    ): CST.FlowScalar | CST.BlockScalar | undefined {\n      let res: CST.FlowScalar | CST.BlockScalar | undefined = undefined\n      CST.visit(cst, ({ key, value }) => {\n        for (const token of [key, value])\n          if (CST.isScalar(token)) {\n            if (token.offset > offset) return CST.visit.BREAK\n            if (\n              token.offset == offset ||\n              (token.offset < offset && token.offset + token.source.length > offset)\n            ) {\n              res = token\n              return CST.visit.BREAK\n            }\n          }\n      })\n      return res\n    }\n    \n\n#### `CST.stringify(cst: Token | CollectionItem): string`\n\nStringify a CST document, token, or collection item. Fair warning: This applies no validation whatsoever, and simply concatenates the sources in their logical order.\n\n#### `CST.visit(cst: CST.Document | CST.CollectionItem, visitor: CSTVisitor)`\n\nApply a visitor to a CST document or item. Effectively, the general-purpose workhorse of navigating the CST.\n\nWalks through the tree (depth-first) starting from `cst` as the root, calling a `visitor` function with two arguments when entering each item:\n\n  * `item`: The current item, which includes the following members: \n    * `start: SourceToken[]` â€“ Source tokens before the key or value, possibly including its anchor or tag.\n    * `key?: Token | null` â€“ Set for pair values. May then be `null`, if the key before the `:` separator is empty.\n    * `sep?: SourceToken[]` â€“ Source tokens between the key and the value, which should include the `:` map value indicator if `value` is set.\n    * `value?: Token` â€“ The value of a sequence item, or of a map pair.\n  * `path`: The steps from the root to the current node, as an array of `['key' | 'value', number]` tuples.\n\n\n\nThe return value of the visitor may be used to control the traversal:\n\n  * `undefined` (default): Do nothing and continue\n  * `CST.visit.SKIP`: Do not visit the children of this token, continue with next sibling\n  * `CST.visit.BREAK`: Terminate traversal completely\n  * `CST.visit.REMOVE`: Remove the current item, then continue with the next one\n  * `number`: Set the index of the next step. This is useful especially if the index of the current token has changed.\n  * `function`: Define the next visitor for this item. After the original visitor is called on item entry, next visitors are called after handling a non-empty `key` and when exiting the item.\n\n\n    \n    \n    const [doc] = new Parser().parse('[ foo, bar, baz ]')\n    CST.visit(doc, (item, path) => {\n      if (!CST.isScalar(item.value)) return\n      const scalar = CST.resolveAsScalar(item.value)\n      if (scalar?.value === 'bar') {\n        const parent = CST.visit.parentCollection(doc, path)\n        const idx = path[path.length - 1][1]\n        const { indent } = item.value\n        parent.items.splice(idx, 0, {\n          start: item.start.slice(),\n          value: CST.createScalarToken('bing', { end: [], indent })\n        })\n        return idx + 2\n      }\n    })\n    \n    CST.stringify(doc)\n    > '[ foo, bing, bar, baz ]'\n    \n\nA couple of utility functions are provided for working with the `path`:\n\n  * `CST.visit.itemAtPath(cst, path): CST.CollectionItem | undefined` â€“ Find the item at `path` from `cst` as the root.\n  * `CST.visit.parentCollection(cst, path): CST.BlockMap | CST.BlockSequence | CST.FlowCollection` â€“ Get the immediate parent collection of the item at `path` from `cst` as the root. Throws an error if the collection is not found, which should never happen if the item itself exists.\n\n\n\n# Errors\n\nNearly all errors and warnings produced by the `yaml` parser functions contain the following fields:\n\nMember | Type | Description  \n---|---|---  \ncode | `string` | An identifier for the error type.  \nlinePos | `[LinePos, LinePos] âŽ®` `undefined` | If `prettyErrors` is enabled and `offset` is known, the one-indexed human-friendly source location `{ line: number, col: number }`.  \nname | `'YAMLParseError' âŽ®` `'YAMLWarning'` |   \nmessage | `string` | A human-readable description of the error  \npos | `[number, number]` | The position in the source at which this error or warning was encountered.  \n  \nA `YAMLParseError` is an error encountered while parsing a source as YAML. They are included in the `doc.errors` array. If that array is not empty when constructing a native representation of a document, the first error will be thrown.\n\nA `YAMLWarning` is not an error, but a spec-mandated warning about unsupported directives or a fallback resolution being used for a node with an unavailable tag. They are included in the `doc.warnings` array.\n\nIn rare cases, the library may produce a more generic error. In particular, `TypeError` may occur when parsing invalid input using the `json` schema, and `ReferenceError` when the `maxAliasCount` limit is enountered.\n\nTo identify errors for special handling, you should primarily use `code` to differentiate them from each other.\n\nCode | Description  \n---|---  \n`ALIAS_PROPS` | Unlike scalars and collections, alias nodes cannot have an anchor or tag associated with it.  \n`BAD_ALIAS` | An alias identifier must be a non-empty sequence of valid characters.  \n`BAD_COLLECTION_TYPE` | Explicit collection tag used on a collection type it does not support.  \n`BAD_DIRECTIVE` | Only the `%YAML` and `%TAG` directives are supported, and they need to follow the specified structure.  \n`BAD_DQ_ESCAPE` | Double-quotes strings may include `\\` escaped content, but that needs to be valid.  \n`BAD_INDENT` | Indentation is important in YAML, and collection items need to all start at the same level. Block scalars are also picky about their leading content.  \n`BAD_PROP_ORDER` | Anchors and tags must be placed after the `?`, `:` and `-` indicators.  \n`BAD_SCALAR_START` | Plain scalars cannot start with a block scalar indicator, or one of the two reserved characters: `@` and ```. To fix, use a block or quoted scalar for the value.  \n`BLOCK_AS_IMPLICIT_KEY` | There's probably something wrong with the indentation, or you're trying to parse something like `a: b: c`, where it's not clear what's the key and what's the value.  \n`BLOCK_IN_FLOW` | YAML scalars and collections both have block and flow styles. Flow is allowed within block, but not the other way around.  \n`DUPLICATE_KEY` | Map keys must be unique. Use the `uniqueKeys` option to disable or customise this check when parsing.  \n`IMPOSSIBLE` | This really should not happen. If you encounter this error code, please file a bug.  \n`KEY_OVER_1024_CHARS` | Due to legacy reasons, implicit keys must have their following `:` indicator after at most 1k characters.  \n`MISSING_CHAR` | Some character or characters are missing here. See the error message for what you need to add.  \n`MULTILINE_IMPLICIT_KEY` | Implicit keys need to be on a single line. Does the input include a plain scalar with a `:` followed by whitespace, which is getting parsed as a map key?  \n`MULTIPLE_ANCHORS` | A node is only allowed to have one anchor.  \n`MULTIPLE_DOCS` | A YAML stream may include multiple documents. If yours does, you'll need to use `parseAllDocuments()` to work with it.  \n`MULTIPLE_TAGS` | A node is only allowed to have one tag.  \n`NON_STRING_KEY` | With the `stringKeys` option, all mapping keys must be strings  \n`TAB_AS_INDENT` | Only spaces are allowed as indentation.  \n`TAG_RESOLVE_FAILED` | Something went wrong when resolving a node's tag with the current schema.  \n`UNEXPECTED_TOKEN` | A token was encountered in a place where it wasn't expected.  \n  \n## Silencing Errors and Warnings\n\nSome of the errors encountered during parsing are required by the spec, but are caused by content that may be parsed unambiguously. To ignore these errors, use the `strict: false` option:\n\n  * `MULTILINE_IMPLICIT_KEY`: Implicit keys of flow sequence pairs need to be on a single line\n  * `KEY_OVER_1024_CHARS`: The : indicator must be at most 1024 chars after the start of an implicit block mapping key\n\n\n\nFor additional control, set the `logLevel` option to `'error'` (default: `'warn'`) to silence all warnings. Setting `logLevel: 'silent'` will ignore parsing errors completely, resulting in output that may well be rather broken.\n\n# Command-line Tool\n    \n    \n    npx yaml valid < file.yaml\n    \n\nAvailable as `npx yaml` or `npm exec yaml`:\n    \n    \n    yaml: A command-line YAML processor and inspector\n    \n    Reads stdin and writes output to stdout and errors & warnings to stderr.\n    \n    Usage:\n      yaml          Process a YAML stream, outputting it as YAML\n      yaml cst      Parse the CST of a YAML stream\n      yaml lex      Parse the lexical tokens of a YAML stream\n      yaml valid    Validate a YAML stream, returning 0 on success\n    \n    Options:\n      --help, -h    Show this message.\n      --json, -j    Output JSON.\n      --indent 2    Output pretty-printed data, indented by the given number of spaces.\n      --merge, -m   Enable support for \"<<\" merge keys.\n    \n    Additional options for bare \"yaml\" command:\n      --doc, -d     Output pretty-printed JS Document objects.\n      --single, -1  Require the input to consist of a single YAML document.\n      --strict, -s  Stop on errors.\n      --visit, -v   Apply a visitor to each document (requires a path to import)\n      --yaml 1.1    Set the YAML version. (default: 1.2)\n    \n\n# YAML Syntax\n\nA YAML _schema_ is a combination of a set of tags and a mechanism for resolving non-specific tags, i.e. values that do not have an explicit tag such as `!!int`. The [default schema](https://eemeli.org/yaml/#data-schemas) is the `'core'` schema, which is the recommended one for YAML 1.2. For YAML 1.1 documents the default is `'yaml-1.1'`.\n\n## Tags\n    \n    \n    YAML.parse('\"42\"')\n    // '42'\n    \n    YAML.parse('!!int \"42\"')\n    // 42\n    \n    YAML.parse(`\n    %TAG ! tag:example.com,2018:app/\n    ---\n    !foo 42\n    `)\n    // YAMLWarning:\n    //   The tag tag:example.com,2018:app/foo is unavailable,\n    //   falling back to tag:yaml.org,2002:str\n    // '42'\n    \n\nThe default prefix for YAML tags is `tag:yaml.org,2002:`, for which the shorthand `!!` is used when stringified. Shorthands for other prefixes may also be defined by document-specific directives, e.g. `!e!` or just `!` for `tag:example.com,2018:app/`, but this is not required to use a tag with a different prefix.\n\nDuring parsing, unresolved tags should not result in errors (though they will be noted as `warnings`), with the tagged value being parsed according to the data type that it would have under automatic tag resolution rules. This should not result in any data loss, allowing such tags to be handled by the calling app.\n\nIn order to have `yaml` provide you with automatic parsing and stringification of non-standard data types, it will need to be configured with a suitable tag object. For more information, see [Custom Tags](https://eemeli.org/yaml/#custom-tags).\n\nThe YAML 1.0 tag specification is [slightly different](https://eemeli.org/yaml/#changes-from-yaml-1-0-to-1-1) from that used in later versions, and implements prefixing shorthands rather differently.\n\n## Version Differences\n\nThis library's parser is based on the 1.2 version of the [YAML spec](http://yaml.org/spec/1.2/spec.html), which is almost completely backwards-compatible with [YAML 1.1](http://yaml.org/spec/1.1/) as well as [YAML 1.0](http://yaml.org/spec/1.0/). Some specific relaxations have been added for backwards compatibility, but if you encounter an issue please [report it](https://github.com/eemeli/yaml/issues).\n\n### Changes from YAML 1.1 to 1.2\n    \n    \n    %YAML 1.1\n    ---\n    true: Yes\n    octal: 014\n    sexagesimal: 3:25:45\n    picture: !!binary |\n      R0lGODlhDAAMAIQAAP//9/X\n      17unp5WZmZgAAAOfn515eXv\n      Pz7Y6OjuDg4J+fn5OTk6enp\n      56enmleECcgggoBADs=\n    \n    \n    \n    { true: true,\n      octal: 12,\n      sexagesimal: 12345,\n      picture:\n       Buffer [Uint8Array] [\n         71, 73, 70, 56, 57, 97, 12, 0, 12, 0, 132, 0, 0,\n         255, 255, 247, 245, 245, 238, 233, 233, 229, 102,\n         102, 102, 0, 0, 0, 231, 231, 231, 94, 94, 94, 243,\n         243, 237, 142, 142, 142, 224, 224, 224, 159, 159,\n         159, 147, 147, 147, 167, 167, 167, 158, 158, 158,\n         105, 94, 16, 39, 32, 130, 10, 1, 0, 59 ] }\n    \n\nThe most significant difference between YAML 1.1 and YAML 1.2 is the introduction of the core data schema as the recommended default, replacing the YAML 1.1 type library:\n\n  * Only `true` and `false` strings are parsed as booleans (including `True` and `TRUE`); `y`, `yes`, `on`, and their negative counterparts are parsed as strings.\n  * Underlines `_` cannot be used within numerical values.\n  * Octal values need a `0o` prefix; e.g. `010` is now parsed with the value 10 rather than 8.\n  * The binary and sexagesimal integer formats have been dropped.\n  * The `!!pairs`, `!!omap`, `!!set`, `!!timestamp` and `!!binary` types have been dropped.\n  * The merge `<<` and value `=` special mapping keys have been removed.\n\n\n\nThe other major change has been to make sure that YAML 1.2 is a valid superset of JSON. Additionally there are some minor differences between the parsing rules:\n\n  * The next-line `\\x85`, line-separator `\\u2028` and paragraph-separator `\\u2029` characters are no longer considered line-break characters. Within scalar values, this means that next-line characters will not be included in the white-space normalisation. Using any of these outside scalar values is likely to result in errors during parsing. For a relatively robust solution, try replacing `\\x85` and `\\u2028` with `\\n` and `\\u2029` with `\\n\\n`.\n  * Tag shorthands can no longer include any of the characters `,[]{}`, but can include `#`. To work around this, either fix your tag names or use verbatim tags.\n  * Anchors can no longer include any of the characters `,[]{}`.\n  * Inside double-quoted strings `\\/` is now a valid escape for the `/` character.\n  * Quoted content can include practically all Unicode characters.\n  * Documents in streams are now independent of each other, and no longer inherit preceding document directives if they do not define their own.\n\n\n\n### Changes from YAML 1.0 to 1.1\n    \n    \n    %YAML:1.0\n    ---\n    date: 2001-01-23\n    number: !int '123'\n    string: !str 123\n    pool: !!ball { number: 8 }\n    invoice: !domain.tld,2002/^invoice\n      customers: !seq\n        - !^customer\n          given : Chris\n          family : Dumars\n    \n\nThe most significant difference between these versions is the complete refactoring of the tag syntax:\n\n  * The `%TAG` directive has been added, along with the `!foo!` tag prefix shorthand notation.\n  * The `^` character no longer enables tag prefixing.\n  * The private vs. default scoping of `!` and `!!` tag prefixes has been switched around; `!!str` is now a default tag while `!bar` is an application-specific tag.\n  * Verbatim `!<baz>` tag notation has been added.\n  * The formal `tag:domain,date/path` format for tag names has been dropped as a requirement.\n\n\n\nAdditionally, the formal description of the language describing the document structure has been completely refactored between these versions, but the described intent has not changed. Other changes include:\n\n  * A `\\` escape has been added for the tab character, in addition to the pre-existing `\\t`\n  * The `\\^` escape has been removed\n  * Directives now use a blank space `' '` rather than `:` as the separator between the name and its parameter/value.\n\n\n\n`yaml@1` supports parsing and stringifying YAML 1.0 documents, but does not expand tags using the `^` notation. As there is no indication that _anyone_ is still using YAML 1.0, explicit support has been dropped in `yaml@2`.\n"
}
